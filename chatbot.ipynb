{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!git clone https://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@github.com/faresabbara/Senior-Project.git"
      ],
      "metadata": {
        "id": "kQu-8RmdpnBq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "L1xAQx3QbNcs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from psutil import virtual_memory\n",
        "\n",
        "# Check GPU\n",
        "gpu_info = tf.config.list_physical_devices('GPU')\n",
        "print(f\"GPU Info: {gpu_info}\")\n",
        "\n",
        "# Check RAM\n",
        "ram_info = virtual_memory()\n",
        "print(f\"Total RAM: {ram_info.total / (1024**3)} GB\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install colab-xterm #https://pypi.org/project/colab-xterm/\n",
        "%load_ext colabxterm\n",
        "\n",
        "!pip install colab-xterm -qqq\n",
        "!pip install langchain -qqq\n",
        "!pip install langchain_community -qqq"
      ],
      "metadata": {
        "id": "GTzPMUX5bSJz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%xterm"
      ],
      "metadata": {
        "id": "cDf8iloRbdJ-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import Ollama module from Langchain\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "# Initialize an instance of the Ollama model\n",
        "llm = Ollama(model=\"llama3\")\n",
        "# Invoke the model to generate responses\n",
        "response = llm.invoke(\"What is the capital of Florida?\")\n",
        "print(response)"
      ],
      "metadata": {
        "id": "CaiRNtYHcEVx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain faiss-cpu sentence-transformers"
      ],
      "metadata": {
        "id": "1boNRfiycNHM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install chromadb\n"
      ],
      "metadata": {
        "id": "GDx9yPf-c32b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-huggingface\n"
      ],
      "metadata": {
        "id": "cp6F9as7c_k-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.llms import Ollama\n",
        "from langchain.chains import RetrievalQA\n",
        "from langchain.vectorstores import Chroma\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.docstore.document import Document\n",
        "from huggingface_hub import login\n",
        "from tqdm import tqdm, trange\n",
        "\n",
        "# Initialize the Llama 3 model\n",
        "llm = Ollama(model=\"llama3\")\n",
        "\n",
        "login(token=\"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\")\n",
        "\n",
        "# Create an embedding model\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Prepare documents\n",
        "documents = [\n",
        "    Document(page_content=\"The capital of Florida is Tallahassee.\", metadata={\"id\": 0}),\n",
        "    Document(page_content=\"Florida is known for its beautiful beaches and warm climate.\", metadata={\"id\": 1}),\n",
        "    Document(page_content=\"The largest city in Florida by population is Jacksonville.\", metadata={\"id\": 2}),\n",
        "    Document(page_content=\"The President of Miami Dade College is President Madeline Pumariega.\", metadata={\"id\": 3}),\n",
        "    Document(page_content=\"The Provost of Miami Dade College is Dr. Malou C. Harrison.\", metadata={\"id\": 4}),\n",
        "    Document(page_content=\"Dr. Ernesto Lee is an AI and Data Analytics Professor on the Kendall Campus at Miami Dade College.\", metadata={\"id\": 5})\n",
        "]\n",
        "\n",
        "# Create Chroma vector store\n",
        "vector_store = Chroma.from_documents(documents, embedding=embeddings)\n",
        "\n",
        "# Load the QA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=vector_store.as_retriever()\n",
        ")"
      ],
      "metadata": {
        "id": "nRh7rseicPY4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Use the QA chain to retrieve relevant documents and generate a response\n",
        "queries = [\n",
        "    \"What is the capital of Florida?\",\n",
        "    \"Who is the President of Miami Dade College?\",\n",
        "    \"Who is the Provost of Miami Dade College?\",\n",
        "    \"Who is Dr. Ernesto Lee?\"\n",
        "]\n",
        "\n",
        "for query in queries:\n",
        "    response = qa_chain.run(query)\n",
        "    print(f\"Query: {query}\\nResponse: {response}\\n\")"
      ],
      "metadata": {
        "id": "sDheWMirewAu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import load_summarize_chain\n",
        "\n",
        "# Load the summarization chain\n",
        "summarization_chain = load_summarize_chain(llm=llm, chain_type=\"map_reduce\")\n",
        "\n",
        "# Summarize a long text\n",
        "long_text = \"\"\"\n",
        "Florida is a state located in the southeastern region of the United States. It is bordered by Alabama to the northwest, Georgia to the north, the Gulf of Mexico to the west, and the Atlantic Ocean to the east. Tallahassee is the state capital, and Jacksonville is the largest city by population. Florida is known for its diverse wildlife, beautiful beaches, and warm climate, making it a popular destination for tourists.\n",
        "\"\"\"\n",
        "summary = summarization_chain({\"input_documents\": [Document(page_content=long_text)]})\n",
        "print(summary)"
      ],
      "metadata": {
        "id": "Pwxz63Qxez0z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "Gg42F254fGI3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# Load the translation pipeline\n",
        "translator = pipeline(\"translation\", model=\"Helsinki-NLP/opus-mt-en-es\")\n",
        "\n",
        "# Translate a text from English to Spanish\n",
        "text_to_translate = \"Florida is known for its beautiful beaches.\"\n",
        "translated_text = translator(text_to_translate)\n",
        "print(translated_text)"
      ],
      "metadata": {
        "id": "pm-wy0fxfLdi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.vectorstores import FAISS  # Or Chroma if set up\n",
        "from langchain_huggingface import HuggingFaceEmbeddings\n",
        "from langchain_community.llms import Ollama\n",
        "\n",
        "# Initialize the Llama 3 model\n",
        "llm = Ollama(model=\"llama3\")\n",
        "\n",
        "# Create embeddings\n",
        "embeddings = HuggingFaceEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# Prepare a retriever with FAISS (or Chroma)\n",
        "documents = [\n",
        "    Document(page_content=\"Florida is a state located in the southeastern region of the United States. The capital of Florida is Tallahassee.\", metadata={\"id\": 0}),\n",
        "]\n",
        "vector_store = FAISS.from_documents(documents, embedding=embeddings)\n",
        "retriever = vector_store.as_retriever()\n",
        "\n",
        "# Initialize the RetrievalQA chain\n",
        "qa_chain = RetrievalQA.from_chain_type(\n",
        "    llm=llm,\n",
        "    chain_type=\"stuff\",\n",
        "    retriever=retriever\n",
        ")\n",
        "\n",
        "# Ask a question\n",
        "question = \"What is the capital of Florida?\"\n",
        "answer = qa_chain({\"query\": question})\n",
        "print(answer)\n"
      ],
      "metadata": {
        "id": "p3k0f1FdfVSO"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}